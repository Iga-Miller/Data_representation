{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e1f645",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b4b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Iga Miller\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e65bd4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39eb517",
   "metadata": {},
   "source": [
    "# 3. Metody tradycyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae633a5",
   "metadata": {},
   "source": [
    "## 3.1. Podział metod tradycyjnych\n",
    "\n",
    "Pierwsze zaproponowane metody uczenia reprezentacji dla danych grafowych były często metodami **transduktywnymi**. Oznacza to m.in., że raz wyuczony model nie jest w stanie wyznaczyć reprezentacji dla wcześniej nieobserwowanych wierzchołków (ang. *unseen nodes*). Implikuje to również, że cały graf musi być przetworzony przez model – nie można wyuczyć funkcji osadzania (embedding) na części grafu i następnie wyznaczać reprezentacje dla konkretnych węzłów. Modele transduktywne nie są stosowane na dużych (wielkoskalowych) grafach ze względu na wybuchającą liczbę parametrów tych modeli.\n",
    "\n",
    "Wśród tradycyjnych metod uczenia reprezentacji dla danych grafowych można wyróżnić metody oparte o:\n",
    "- błądzenia losowe (ang. *random-walks*) – np. DeepWalk, Node2vec,\n",
    "- faktoryzację macierzy (ang. *matrix factorization*) – np. HOPE, Graph Factorization, GraRep,\n",
    "- grafowe macierze Laplace'a (ang. *graph Laplacians*) – np. Laplacian Eigenmaps, Local Linear Embedding,\n",
    "- uczenie głębokie – SDNE, DNGR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20be44",
   "metadata": {},
   "source": [
    "## 3.2. Metody oparte o błądzenia losowe\n",
    "\n",
    "Omówienie wszystkich metod wykracza poza zakres kursu, ale spróbujemy uruchomić i zbadać dwie wybrane metody oparte o błądzenia losowe, mianowicie **DeepWalk** oraz **Node2vec**. Są to dwie koncepcyjnie bardzo podobne metody. Idea stojąca za tymi metodami jest oparta na modelu word2vec, znanym z dziedziny przetwarzania języka naturalnego. Word2vec wyznacza wektory reprezentacji dla słów w podanym tekście, natomiast w przypadku grafów nie mamy \"zdań\". Jak zatem zmodyfikować ten algorytm, aby mógł przetwarzać grafy? Na to pytanie po raz pierwszy próbowali odpowiedzieć autorzy metody DeepWalk. Ich rozwiązaniem było próbkowanie grafu za pomocą błądzeń losowych, z których otrzymywali sekwencje wierzchołków. Te sekwencje traktowali jako zdania, w których słowami są wierzchołki. Następnie można było bez problemu zastosować metodę word2vec.\n",
    "\n",
    "**Uwaga:** Zauważmy, że word2vec nie zwraca uwagi za \"treść\" słów, a jedynie na *współwystępowanie* słów. Można zatem stosować algorytm word2vec dla dowolnych obiektów o ile można dla nich określić koncepcję współwystępowania.\n",
    "\n",
    "Pojedyncze błądzenie losowe można opisać za pomocą algorytmu:\n",
    "1. Rozpocznij od zadanego wierzchołka $u$.\n",
    "2. Wyznacz zbiór sąsiadów: $\\mathcal{N}_u = \\{v: (u, v) \\in \\mathcal{E}\\}$.\n",
    "3. Ze zbioru sąsiadów $\\mathcal{N}_u$ wylosuj jeden element $v$ w oparciu o zadany rozkład prawdopodobieństwa.\n",
    "4. Wróć do kroku 2, ale wyznacz sąsiedztwo wierzchołka $v$. Powtarzaj dopóki nie osiągniesz zadanej długości błądzenia, bądź $\\mathcal{N}_u = \\emptyset$.\n",
    "\n",
    "W trakcie przeprowadzania błądzenia losowego zapisywane są kolejno rozważane wierzchołki w postaci sekwencji wierzchołków.\n",
    "\n",
    "\n",
    "Podsumowując, metoda DeepWalk działa w następujący sposób:\n",
    "1. Z każdego wierzchołka w grafie rozpocznij błądzenie losowe (z losowaniem sąsiadów opartym na rozkładzie jednostajnym). Wylicz kilka takich błądzeń losowych (hiperparametr metody) o zadanych długościach błądzenia (hiperparametr metody).\n",
    "2. Zainicjalizuj losowo macierz reprezentacji $\\mathbf{Z} \\in \\mathbb{R}^{|\\mathcal{V}| \\times d}$.\n",
    "3. Wyznacz pozytywne pary wierzchołków (współwystępujące w błądzeniach losowych, zastosuj kontekst / okno o zadanej długości – hiperparametr metody).\n",
    "4. Wylosuj zbiór negatywne pary wierzchołków (liczność zbioru jest hiperparametrem metody).\n",
    "5. Użyj macierzy reprezentacji oraz pozytywnych i negatywnych par, aby zoptymalizować funkcję kosztu modelu word2vec.\n",
    "\n",
    "**Uwaga:** Posiadanie (statycznej) macierzy reprezentacji, w której każdy wiersz oznacza reprezentację danego wierzchołka, powoduje, że: (a) metoda nie skaluje się dobrze dla dużych grafów, (b) jest to metoda transduktywna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c0448",
   "metadata": {},
   "source": [
    "Metoda **Node2vec** jest koncepcyjnie bardzo podobna do metody DeepWalk, z taką różnicą, że wprowadzone zostały dwa nowe hiperparametry $p$ oraz $q$, które pozwalają zmieniać zachowanie błądzeń losowych poprzez nadawanie różnych wag sąsiadom danego wierzchołka. Dobierając odpowiednio wartości tych parametrów, błądzenia mogą eksplorować graf na zasadzie przeglądu wszerz (ang. *Breadth-First Search*) albo wgłąb (ang. *Depth-First Search*). Co więcej przymując parametry $p = 1$ oraz $q = 1$ metoda Node2vec jest równoważna z metodą DeepWalk. Stąd też w bibliotece PyTorch-Geometric posiadamy tylko implementację pod nazwą Node2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1864b4",
   "metadata": {},
   "source": [
    "## 3.3. DeepWalk\n",
    "\n",
    "Uruchomimy teraz metodą DeepWalk na zbiorze Cora i zwizualizujemy otrzymane wektory reprezentacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7140d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "data = Planetoid(root=\"./data/\", name=\"Cora\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7fdc204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">List</span><span class=\"p\">,</span> <span class=\"n\">Tuple</span>\n",
       "\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">torch_geometric.nn.models</span> <span class=\"kn\">import</span> <span class=\"n\">Node2Vec</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tqdm.auto</span> <span class=\"kn\">import</span> <span class=\"n\">tqdm</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">train_random_walk_model</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">edge_index</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">p</span><span class=\"p\">:</span> <span class=\"nb\">float</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">q</span><span class=\"p\">:</span> <span class=\"nb\">float</span><span class=\"p\">,</span>\n",
       "\n",
       "    <span class=\"c1\"># Default training params</span>\n",
       "    <span class=\"n\">num_epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">100</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">256</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">learning_rate</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-2</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">4</span><span class=\"p\">,</span>\n",
       "\n",
       "    <span class=\"c1\"># Default method params</span>\n",
       "    <span class=\"n\">embedding_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">128</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">walk_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">20</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">context_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">walks_per_node</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">num_negative_samples</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n",
       "\n",
       "    <span class=\"c1\"># Progress bars</span>\n",
       "    <span class=\"n\">quiet</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">Node2Vec</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]]:</span>\n",
       "    <span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s2\">&quot;cuda&quot;</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s2\">&quot;cpu&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Build model</span>\n",
       "    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Node2Vec</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">edge_index</span><span class=\"o\">=</span><span class=\"n\">edge_index</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">embedding_dim</span><span class=\"o\">=</span><span class=\"n\">embedding_dim</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">walk_length</span><span class=\"o\">=</span><span class=\"n\">walk_length</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">context_size</span><span class=\"o\">=</span><span class=\"n\">context_size</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">walks_per_node</span><span class=\"o\">=</span><span class=\"n\">walks_per_node</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">p</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">q</span><span class=\"o\">=</span><span class=\"n\">q</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">num_negative_samples</span><span class=\"o\">=</span><span class=\"n\">num_negative_samples</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">quiet</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">num_parameters</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">numel</span><span class=\"p\">()</span>\n",
       "        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Liczba parametrów modelu: </span><span class=\"si\">{</span><span class=\"n\">num_parameters</span><span class=\"si\">:</span><span class=\"s2\">,</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Training</span>\n",
       "    <span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">loader</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"n\">num_workers</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "    <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"n\">learning_rate</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n",
       "    <span class=\"n\">losses</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "\n",
       "    <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"n\">tqdm</span><span class=\"p\">(</span><span class=\"n\">iterable</span><span class=\"o\">=</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_epochs</span><span class=\"p\">),</span> <span class=\"n\">desc</span><span class=\"o\">=</span><span class=\"s2\">&quot;Epochs&quot;</span><span class=\"p\">,</span> <span class=\"n\">disable</span><span class=\"o\">=</span><span class=\"n\">quiet</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">total_loss</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n",
       "\n",
       "        <span class=\"k\">for</span> <span class=\"n\">pos_rw</span><span class=\"p\">,</span> <span class=\"n\">neg_rw</span> <span class=\"ow\">in</span> <span class=\"n\">loader</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n",
       "\n",
       "            <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">loss</span><span class=\"p\">(</span><span class=\"n\">pos_rw</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">),</span> <span class=\"n\">neg_rw</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n",
       "\n",
       "            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n",
       "\n",
       "            <span class=\"n\">total_loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n",
       "\n",
       "        <span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">total_loss</span> <span class=\"o\">/</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">loader</span><span class=\"p\">))</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">losses</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">get_representations</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">Node2Vec</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n",
       "    <span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n",
       "        <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">cpu</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">()</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">z</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{typing} \\PY{k+kn}{import} \\PY{n}{List}\\PY{p}{,} \\PY{n}{Tuple}\n",
       "\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{torch\\PYZus{}geometric}\\PY{n+nn}{.}\\PY{n+nn}{nn}\\PY{n+nn}{.}\\PY{n+nn}{models} \\PY{k+kn}{import} \\PY{n}{Node2Vec}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tqdm}\\PY{n+nn}{.}\\PY{n+nn}{auto} \\PY{k+kn}{import} \\PY{n}{tqdm}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{train\\PYZus{}random\\PYZus{}walk\\PYZus{}model}\\PY{p}{(}\n",
       "    \\PY{n}{edge\\PYZus{}index}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{,}\n",
       "    \\PY{n}{p}\\PY{p}{:} \\PY{n+nb}{float}\\PY{p}{,}\n",
       "    \\PY{n}{q}\\PY{p}{:} \\PY{n+nb}{float}\\PY{p}{,}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Default training params}\n",
       "    \\PY{n}{num\\PYZus{}epochs}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{100}\\PY{p}{,}\n",
       "    \\PY{n}{batch\\PYZus{}size}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{256}\\PY{p}{,}\n",
       "    \\PY{n}{learning\\PYZus{}rate}\\PY{p}{:} \\PY{n+nb}{float} \\PY{o}{=} \\PY{l+m+mf}{1e\\PYZhy{}2}\\PY{p}{,}\n",
       "    \\PY{n}{num\\PYZus{}workers}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{4}\\PY{p}{,}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Default method params}\n",
       "    \\PY{n}{embedding\\PYZus{}dim}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{128}\\PY{p}{,}\n",
       "    \\PY{n}{walk\\PYZus{}length}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{20}\\PY{p}{,}\n",
       "    \\PY{n}{context\\PYZus{}size}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{5}\\PY{p}{,}\n",
       "    \\PY{n}{walks\\PYZus{}per\\PYZus{}node}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{1}\\PY{p}{,}\n",
       "    \\PY{n}{num\\PYZus{}negative\\PYZus{}samples}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{l+m+mi}{1}\\PY{p}{,}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Progress bars}\n",
       "    \\PY{n}{quiet}\\PY{p}{:} \\PY{n+nb}{bool} \\PY{o}{=} \\PY{k+kc}{False}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{Tuple}\\PY{p}{[}\\PY{n}{Node2Vec}\\PY{p}{,} \\PY{n}{List}\\PY{p}{[}\\PY{n+nb}{float}\\PY{p}{]}\\PY{p}{]}\\PY{p}{:}\n",
       "    \\PY{n}{device} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{device}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{cuda}\\PY{l+s+s2}{\\PYZdq{}} \\PY{k}{if} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{cuda}\\PY{o}{.}\\PY{n}{is\\PYZus{}available}\\PY{p}{(}\\PY{p}{)} \\PY{k}{else} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{cpu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Build model}\n",
       "    \\PY{n}{model} \\PY{o}{=} \\PY{n}{Node2Vec}\\PY{p}{(}\n",
       "        \\PY{n}{edge\\PYZus{}index}\\PY{o}{=}\\PY{n}{edge\\PYZus{}index}\\PY{p}{,}\n",
       "        \\PY{n}{embedding\\PYZus{}dim}\\PY{o}{=}\\PY{n}{embedding\\PYZus{}dim}\\PY{p}{,}\n",
       "        \\PY{n}{walk\\PYZus{}length}\\PY{o}{=}\\PY{n}{walk\\PYZus{}length}\\PY{p}{,}\n",
       "        \\PY{n}{context\\PYZus{}size}\\PY{o}{=}\\PY{n}{context\\PYZus{}size}\\PY{p}{,}\n",
       "        \\PY{n}{walks\\PYZus{}per\\PYZus{}node}\\PY{o}{=}\\PY{n}{walks\\PYZus{}per\\PYZus{}node}\\PY{p}{,}\n",
       "        \\PY{n}{p}\\PY{o}{=}\\PY{n}{p}\\PY{p}{,}\n",
       "        \\PY{n}{q}\\PY{o}{=}\\PY{n}{q}\\PY{p}{,}\n",
       "        \\PY{n}{num\\PYZus{}negative\\PYZus{}samples}\\PY{o}{=}\\PY{n}{num\\PYZus{}negative\\PYZus{}samples}\\PY{p}{,}\n",
       "    \\PY{p}{)}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{if} \\PY{o+ow}{not} \\PY{n}{quiet}\\PY{p}{:}\n",
       "        \\PY{n}{num\\PYZus{}parameters} \\PY{o}{=} \\PY{n+nb}{list}\\PY{p}{(}\\PY{n}{model}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{o}{.}\\PY{n}{numel}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n+nb}{print}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Liczba parametrów modelu: }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{num\\PYZus{}parameters}\\PY{l+s+si}{:}\\PY{l+s+s2}{,}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Training}\n",
       "    \\PY{n}{loader} \\PY{o}{=} \\PY{n}{model}\\PY{o}{.}\\PY{n}{loader}\\PY{p}{(}\n",
       "        \\PY{n}{batch\\PYZus{}size}\\PY{o}{=}\\PY{n}{batch\\PYZus{}size}\\PY{p}{,}\n",
       "        \\PY{n}{shuffle}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,}\n",
       "        \\PY{n}{num\\PYZus{}workers}\\PY{o}{=}\\PY{n}{num\\PYZus{}workers}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "    \\PY{n}{optimizer} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{optim}\\PY{o}{.}\\PY{n}{Adam}\\PY{p}{(}\\PY{n}{model}\\PY{o}{.}\\PY{n}{parameters}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,} \\PY{n}{lr}\\PY{o}{=}\\PY{n}{learning\\PYZus{}rate}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n}{model}\\PY{o}{.}\\PY{n}{train}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n}{losses} \\PY{o}{=} \\PY{p}{[}\\PY{p}{]}\n",
       "\n",
       "    \\PY{k}{for} \\PY{n}{\\PYZus{}} \\PY{o+ow}{in} \\PY{n}{tqdm}\\PY{p}{(}\\PY{n}{iterable}\\PY{o}{=}\\PY{n+nb}{range}\\PY{p}{(}\\PY{n}{num\\PYZus{}epochs}\\PY{p}{)}\\PY{p}{,} \\PY{n}{desc}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Epochs}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{disable}\\PY{o}{=}\\PY{n}{quiet}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{total\\PYZus{}loss} \\PY{o}{=} \\PY{l+m+mi}{0}\n",
       "\n",
       "        \\PY{k}{for} \\PY{n}{pos\\PYZus{}rw}\\PY{p}{,} \\PY{n}{neg\\PYZus{}rw} \\PY{o+ow}{in} \\PY{n}{loader}\\PY{p}{:}\n",
       "            \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{zero\\PYZus{}grad}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "            \\PY{n}{loss} \\PY{o}{=} \\PY{n}{model}\\PY{o}{.}\\PY{n}{loss}\\PY{p}{(}\\PY{n}{pos\\PYZus{}rw}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\\PY{p}{,} \\PY{n}{neg\\PYZus{}rw}\\PY{o}{.}\\PY{n}{to}\\PY{p}{(}\\PY{n}{device}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{loss}\\PY{o}{.}\\PY{n}{backward}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "            \\PY{n}{optimizer}\\PY{o}{.}\\PY{n}{step}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "            \\PY{n}{total\\PYZus{}loss} \\PY{o}{+}\\PY{o}{=} \\PY{n}{loss}\\PY{o}{.}\\PY{n}{item}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "        \\PY{n}{losses}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n}{total\\PYZus{}loss} \\PY{o}{/} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{loader}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{model}\\PY{p}{,} \\PY{n}{losses}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{get\\PYZus{}representations}\\PY{p}{(}\\PY{n}{model}\\PY{p}{:} \\PY{n}{Node2Vec}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{:}\n",
       "    \\PY{n}{model}\\PY{o}{.}\\PY{n}{eval}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{k}{with} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{no\\PYZus{}grad}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{z} \\PY{o}{=} \\PY{n}{model}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{cpu}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{detach}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{z}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "from typing import List, Tuple\n",
       "\n",
       "import torch\n",
       "from torch_geometric.nn.models import Node2Vec\n",
       "from tqdm.auto import tqdm\n",
       "\n",
       "\n",
       "def train_random_walk_model(\n",
       "    edge_index: torch.Tensor,\n",
       "    p: float,\n",
       "    q: float,\n",
       "\n",
       "    # Default training params\n",
       "    num_epochs: int = 100,\n",
       "    batch_size: int = 256,\n",
       "    learning_rate: float = 1e-2,\n",
       "    num_workers: int = 4,\n",
       "\n",
       "    # Default method params\n",
       "    embedding_dim: int = 128,\n",
       "    walk_length: int = 20,\n",
       "    context_size: int = 5,\n",
       "    walks_per_node: int = 1,\n",
       "    num_negative_samples: int = 1,\n",
       "\n",
       "    # Progress bars\n",
       "    quiet: bool = False,\n",
       ") -> Tuple[Node2Vec, List[float]]:\n",
       "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
       "\n",
       "    # Build model\n",
       "    model = Node2Vec(\n",
       "        edge_index=edge_index,\n",
       "        embedding_dim=embedding_dim,\n",
       "        walk_length=walk_length,\n",
       "        context_size=context_size,\n",
       "        walks_per_node=walks_per_node,\n",
       "        p=p,\n",
       "        q=q,\n",
       "        num_negative_samples=num_negative_samples,\n",
       "    ).to(device)\n",
       "\n",
       "    if not quiet:\n",
       "        num_parameters = list(model.parameters())[0].numel()\n",
       "        print(f\"Liczba parametrów modelu: {num_parameters:,}\")\n",
       "\n",
       "    # Training\n",
       "    loader = model.loader(\n",
       "        batch_size=batch_size,\n",
       "        shuffle=True,\n",
       "        num_workers=num_workers,\n",
       "    )\n",
       "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
       "\n",
       "    model.train()\n",
       "    losses = []\n",
       "\n",
       "    for _ in tqdm(iterable=range(num_epochs), desc=\"Epochs\", disable=quiet):\n",
       "        total_loss = 0\n",
       "\n",
       "        for pos_rw, neg_rw in loader:\n",
       "            optimizer.zero_grad()\n",
       "\n",
       "            loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
       "            loss.backward()\n",
       "\n",
       "            optimizer.step()\n",
       "\n",
       "            total_loss += loss.item()\n",
       "\n",
       "        losses.append(total_loss / len(loader))\n",
       "\n",
       "    return model, losses\n",
       "\n",
       "\n",
       "def get_representations(model: Node2Vec) -> torch.Tensor:\n",
       "    model.eval()\n",
       "    with torch.no_grad():\n",
       "        z = model().cpu().detach()\n",
       "\n",
       "    return z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Code, display\n",
    "\n",
    "\n",
    "display(Code(\"random_walk_model.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5e25ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`Node2Vec` requires `torch-cluster`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom_walk_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_random_walk_model\n\u001b[1;32m----> 3\u001b[0m deepwalk, train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_random_walk_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Pulpit\\Studia_mgr_SI\\Reprezentacja_wiedzy\\l03-czw-15-Iga-Miller\\random_walk_model.py:32\u001b[0m, in \u001b[0;36mtrain_random_walk_model\u001b[1;34m(edge_index, p, q, num_epochs, batch_size, learning_rate, num_workers, embedding_dim, walk_length, context_size, walks_per_node, num_negative_samples, quiet)\u001b[0m\n\u001b[0;32m     29\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Build model\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNode2Vec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwalks_per_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwalks_per_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_negative_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_negative_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[0;32m     44\u001b[0m     num_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[1;32m~\\OneDrive\\Pulpit\\Studia_mgr_SI\\venv\\lib\\site-packages\\torch_geometric\\nn\\models\\node2vec.py:66\u001b[0m, in \u001b[0;36mNode2Vec.__init__\u001b[1;34m(self, edge_index, embedding_dim, walk_length, context_size, walks_per_node, p, q, num_negative_samples, num_nodes, sparse)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random_walk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Node2Vec` requires `torch-cluster`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     68\u001b[0m N \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m     69\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index\n",
      "\u001b[1;31mImportError\u001b[0m: `Node2Vec` requires `torch-cluster`."
     ]
    }
   ],
   "source": [
    "from random_walk_model import train_random_walk_model\n",
    "\n",
    "deepwalk, train_losses = train_random_walk_model(edge_index=data.edge_index, p=1.0, q=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad87399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(range(len(train_losses)), train_losses, linestyle=\"--\", marker=\"o\")\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "from random_walk_model import get_representations\n",
    "\n",
    "\n",
    "z = get_representations(deepwalk)\n",
    "\n",
    "z_PCA = PCA(n_components=2).fit_transform(z)\n",
    "z_UMAP = UMAP(n_components=2).fit_transform(z)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "sns.scatterplot(x=z_PCA[:, 0], y=z_PCA[:, 1], hue=data.y, palette=\"Set2\", ax=axs[0])\n",
    "axs[0].set(title=\"PCA\")\n",
    "sns.scatterplot(x=z_UMAP[:, 0], y=z_UMAP[:, 1], hue=data.y, palette=\"Set2\", ax=axs[1])\n",
    "axs[1].set(title=\"UMAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3d806",
   "metadata": {},
   "source": [
    "Zaimportujemy funkcje z poprzedniego zeszytu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60061bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"2. Zadania w przetwarzaniu grafów.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd7fa2",
   "metadata": {},
   "source": [
    "## 3.4. Ewaluacja w zadaniach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c80e60",
   "metadata": {},
   "source": [
    "**Klasyfikacja węzłów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_metrics = evaluate_node_classification(data=data, z=z)\n",
    "\n",
    "print(\"-- Node classification --\")\n",
    "print(f\"Train AUC: {nc_metrics['train_auc'] * 100.:.2f} [%]\")\n",
    "print(f\"Test AUC: {nc_metrics['test_auc'] * 100.:.2f} [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a575d",
   "metadata": {},
   "source": [
    "**Predykcja krawędzi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_dataset = prepare_train_test_sets(edge_index=data.edge_index)\n",
    "\n",
    "lp_deepwalk, _ = train_random_walk_model(\n",
    "    edge_index=lp_dataset[\"train_edges_pos\"], \n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    num_epochs=100,\n",
    ")\n",
    "\n",
    "lp_z = get_representations(lp_deepwalk)\n",
    "\n",
    "lp_metrics = evaluate_link_prediction(\n",
    "    train_edges=lp_dataset[\"train_edges\"],\n",
    "    y_train=lp_dataset[\"y_train\"],\n",
    "    test_edges=lp_dataset[\"test_edges\"],\n",
    "    y_test=lp_dataset[\"y_test\"],\n",
    "    transformation_name=\"average\",\n",
    "    z=lp_z,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"-- Link prediction --\")\n",
    "print(f\"Train AUC: {lp_metrics['train_auc'] * 100.:.2f} [%]\")\n",
    "print(f\"Test AUC: {lp_metrics['test_auc'] * 100.:.2f} [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575186e",
   "metadata": {},
   "source": [
    "**Klasyfikacja grafów**\n",
    "\n",
    "Dla zadania klasyfikacji grafów użyjemy zbioru ENZYMES, w którym każdy graf reprezentuje pojedynczy enzym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "enzymes = TUDataset(root=\"./data\", name=\"ENZYMES\")\n",
    "\n",
    "print(f\"Liczba grafów: {len(enzymes)}\")\n",
    "\n",
    "enzymes_subset, _ = train_test_split(\n",
    "    [e for e in enzymes], \n",
    "    train_size=0.1, \n",
    "    stratify=[e.y.item() for e in enzymes],\n",
    ")\n",
    "print(f\"Ograniczymy liczbę grafów do {len(enzymes_subset)}\")\n",
    "\n",
    "z = []\n",
    "\n",
    "for enzyme in tqdm(enzymes_subset, desc=\"Embedding graphs\"):\n",
    "    model, _ = train_random_walk_model(\n",
    "        edge_index=enzyme.edge_index,\n",
    "        p=1.0,\n",
    "        q=1.0,\n",
    "        num_epochs=10,\n",
    "        quiet=True,\n",
    "    )\n",
    "    \n",
    "    z.append(get_representations(model))\n",
    "        \n",
    "        \n",
    "y = torch.tensor([e.y for e in enzymes_subset])\n",
    "\n",
    "gc_metrics = evaluate_graph_classification(z, y, transformation_name=\"average\")\n",
    "\n",
    "print(\"-- Graph classification --\")\n",
    "print(f\"Train AUC: {gc_metrics['train_auc'] * 100.:.2f} [%]\")\n",
    "print(f\"Test AUC: {gc_metrics['test_auc'] * 100.:.2f} [%]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
